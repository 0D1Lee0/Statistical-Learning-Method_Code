前言
====

力求每行代码都有注释，重要部分注明公式来源。具体会追求下方这样的代码，学习者可以照着公式看程序，让代码有据可查。

![image](https://github.com/Dod-o/Statistical-Learning-Method_Code/blob/master/CodePic.png)

    
如果时间充沛的话，可能会试着给每一章写一篇博客。先放个博客链接吧：[传送门](http://www.pkudodo.com/)。    

##### 注：其中Mnist数据集已转换为csv格式，由于体积为107M超过限制，改为压缩包形式。下载后务必先将Mnist文件内压缩包直接解压。   

       
       
实现
======

### 第二章 感知机：
博客：[统计学习方法|感知机原理剖析及实现](http://www.pkudodo.com/2018/11/18/%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e6%96%b9%e6%b3%95%e6%84%9f%e7%9f%a5%e6%9c%ba%e5%8e%9f%e7%90%86%e5%8f%8a%e5%ae%9e%e7%8e%b0%e5%89%96%e6%9e%90/)      
实现：[Statistical-Learning-Method_Code/perceptron/perceptron_dichotomy.py](https://github.com/Dod-o/Statistical-Learning-Method_Code/blob/master/perceptron/perceptron_dichotomy.py)
      
### 第三章 K近邻：
博客：[统计学习方法|K近邻原理剖析及实现](http://www.pkudodo.com/2018/11/19/%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e6%96%b9%e6%b3%95k%e8%bf%91%e9%82%bb%e5%8e%9f%e7%90%86%e5%89%96%e6%9e%90%e5%8f%8a%e5%ae%9e%e8%b7%b5/?preview_id=194&preview_nonce=a52c4627bb&_thumbnail_id=-1&preview=true)      
[Statistical-Learning-Method_Code/KNN/KNN.py](https://github.com/Dod-o/Statistical-Learning-Method_Code/blob/master/KNN/KNN.py)
      
### 第四章 朴素贝叶斯：
[Statistical-Learning-Method_Code/NaiveBayes/NaiveBayes.py](https://github.com/Dod-o/Statistical-Learning-Method_Code/blob/master/NaiveBayes/NaiveBayes.py)    

